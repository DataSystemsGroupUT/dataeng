{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Data Ingestion (Kafka)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://camo.githubusercontent.com/56166d361c3975dee750ecce16d605bbbf66516b/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f352f35332f4170616368655f6b61666b615f776f7264747970652e737667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student ID: [#####]\n",
    "### Subtasks Done: [#,#,..]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with sensor data\n",
    "\n",
    "We want to monitor the status of three smart buildings.\n",
    "Each building has 8 floors and each floor has 20 rooms, that have a max capacity of 10 people each.\n",
    "\n",
    "Rooms are equipped with sensors that counts how many people are currently inside the rooms. \n",
    "\n",
    "Due to COVID-19, we want monitor how many people are in the various rooms, floors, and buildings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./buildings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes before starting!!!\n",
    " \n",
    "- Look at the whole notebook (tasks) before starting\n",
    "    - (Hint: task 2 and 3 depends on 0 and 1)\n",
    "- you can create as many topics as you want \n",
    "    - (Hint 3 or more)\n",
    "- each topic in the exercise should have **at least** 2 partitions. \n",
    "    - (HINT: to decide how many partition look at task 3)\n",
    "- we assume a replication factor of 1 for all the topics is sufficient.\n",
    "- The minimal required dependencies have been already imported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Setting the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import SerializingProducer, DeserializingConsumer\n",
    "from confluent_kafka.serialization import StringSerializer, StringDeserializer\n",
    "from confluent_kafka.serialization import IntegerSerializer, IntegerDeserializer\n",
    "from confluent_kafka.admin import AdminClient, NewTopic, NewPartitions\n",
    "from uuid import uuid4\n",
    "import sys, lorem, random, time, json, csv\n",
    "\n",
    "brokers = \"kafka1:9092,kafka2:9093\"\n",
    "topics = [\"ingestion2\", \"by_floor\", \"by_building\"] ## Add here your topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create new topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ingestion': <Future at 0x7f71d43e1550 state=running>,\n",
       " 'by_floor': <Future at 0x7f71d43e1460 state=running>,\n",
       " 'by_building': <Future at 0x7f71d43e1670 state=running>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_topics = [NewTopic(topic, num_partitions=3, replication_factor=1) for topic in topics]\n",
    "a = AdminClient({'bootstrap.servers': brokers})\n",
    "\n",
    "a.create_topics(new_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parts = [NewPartitions(topics[0], int(24))]\n",
    "fs = a.create_partitions(new_parts, validate_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buildings\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2)])\n",
      "t4\n",
      "dict_values([PartitionMetadata(0)])\n",
      "by_floor\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2)])\n",
      "by_building\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2)])\n",
      "_schemas\n",
      "dict_values([PartitionMetadata(0)])\n",
      "t3\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1)])\n",
      "floors1\n",
      "dict_values([PartitionMetadata(0)])\n",
      "rooms\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2)])\n",
      "__consumer_offsets\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2), PartitionMetadata(3), PartitionMetadata(4), PartitionMetadata(5), PartitionMetadata(6), PartitionMetadata(7), PartitionMetadata(8), PartitionMetadata(9), PartitionMetadata(10), PartitionMetadata(11), PartitionMetadata(12), PartitionMetadata(13), PartitionMetadata(14), PartitionMetadata(15), PartitionMetadata(16), PartitionMetadata(17), PartitionMetadata(18), PartitionMetadata(19), PartitionMetadata(20), PartitionMetadata(21), PartitionMetadata(22), PartitionMetadata(23), PartitionMetadata(24), PartitionMetadata(25), PartitionMetadata(26), PartitionMetadata(27), PartitionMetadata(28), PartitionMetadata(29), PartitionMetadata(30), PartitionMetadata(31), PartitionMetadata(32), PartitionMetadata(33), PartitionMetadata(34), PartitionMetadata(35), PartitionMetadata(36), PartitionMetadata(37), PartitionMetadata(38), PartitionMetadata(39), PartitionMetadata(40), PartitionMetadata(41), PartitionMetadata(42), PartitionMetadata(43), PartitionMetadata(44), PartitionMetadata(45), PartitionMetadata(46), PartitionMetadata(47), PartitionMetadata(48), PartitionMetadata(49)])\n",
      "t2\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1)])\n",
      "people_per_building\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1)])\n",
      "sensor_readings\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1)])\n",
      "ingestion\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2), PartitionMetadata(3), PartitionMetadata(4), PartitionMetadata(5), PartitionMetadata(6), PartitionMetadata(7), PartitionMetadata(8), PartitionMetadata(9), PartitionMetadata(10), PartitionMetadata(11), PartitionMetadata(12), PartitionMetadata(13), PartitionMetadata(14), PartitionMetadata(15), PartitionMetadata(16), PartitionMetadata(17), PartitionMetadata(18), PartitionMetadata(19), PartitionMetadata(20), PartitionMetadata(21), PartitionMetadata(22), PartitionMetadata(23)])\n",
      "build1\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2), PartitionMetadata(3), PartitionMetadata(4)])\n",
      "build3\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2), PartitionMetadata(3), PartitionMetadata(4)])\n",
      "floors\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2)])\n",
      "_confluent-metrics\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2), PartitionMetadata(3), PartitionMetadata(4), PartitionMetadata(5), PartitionMetadata(6), PartitionMetadata(7), PartitionMetadata(8), PartitionMetadata(9), PartitionMetadata(10), PartitionMetadata(11)])\n",
      "people_per_floor\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1)])\n",
      "build2\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1), PartitionMetadata(2), PartitionMetadata(3), PartitionMetadata(4)])\n",
      "__confluent.support.metrics\n",
      "dict_values([PartitionMetadata(0)])\n",
      "t1\n",
      "dict_values([PartitionMetadata(0), PartitionMetadata(1)])\n"
     ]
    }
   ],
   "source": [
    "for t in a.list_topics().topics.values():\n",
    "    print(t)\n",
    "    print(t.partitions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Counting People\n",
    "\n",
    "Write a Kafka Producer that generates the observations every 5 seconds (system time)\n",
    "for each building, floor, and room, and pushes them to a topic.\n",
    "\n",
    "We recommend \"murmur2_random\" as partitioner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate the topics with 1000 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pconf = {\n",
    "    'bootstrap.servers': brokers,\n",
    "    'partitioner': 'murmur2_random',\n",
    "    'key.serializer': StringSerializer('utf_8'),\n",
    "    'value.serializer':  StringSerializer()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = SerializingProducer(pconf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate a topic with the 1000 observations in obs.csv, sending one every 5 seconds (system time)\n",
    "\n",
    "#### Hints:\n",
    "- represent the message as a json\n",
    "- use the a random key (check the json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('obs.csv', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with f:\n",
    "    reader = csv.reader(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%% Aborted by user\n"
     ]
    }
   ],
   "source": [
    "f = open('obs.csv', 'r')\n",
    "with f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        try:\n",
    "    \n",
    "            k = { 'building': row[2], 'floor': row[3] }\n",
    "            v = { 'count': row[1], 'uuid': row[0], 'room': row[4]}\n",
    "\n",
    "            p.produce(topics[0], key=json.dumps(k), value=json.dumps(v))\n",
    "            p.poll(0)\n",
    "            p.flush()\n",
    "            time.sleep(5)\n",
    "        except KeyboardInterrupt:\n",
    "            sys.stderr.write('%% Aborted by user\\n')\n",
    "        except BufferError:\n",
    "            sys.stderr.write('%% Local producer queue is full (%d messages awaiting delivery): try again\\n' % len(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Reading observations\n",
    "\n",
    "Write a Kafka Consumer that reads the previous topic and prints the result out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_conf = {\n",
    "    'bootstrap.servers': brokers,\n",
    "    ## Your Configuration Code Here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your CONSUMER Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consume 1000 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in range(0,1000):\n",
    "        ## Your consuming Code Here\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')\n",
    "finally:\n",
    "    # Close down consumer to commit final offsets.\n",
    "    consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Aggregating the number of people \n",
    "\n",
    "Write a Kafka Consumer that reads the previous topics and count\n",
    "the number of people per floor and per building every minute,\n",
    "\n",
    "Always ensure the result are durable (save them in a topic)\n",
    "\n",
    "Carry on the minimal ammount of information in the key and the value (remove unnecessary information)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HINT: How did you organize the data in partitions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the message key to simplify counting by floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_conf = {\n",
    "    'bootstrap.servers': brokers,\n",
    "    ## Your Configuration Code Here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your consumer Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pconf = {\n",
    "    'bootstrap.servers': brokers,\n",
    "       ## Your Configuration Code Here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your producer Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in range(0,1000):\n",
    "          # Your consuming and producing code here\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of people Per Floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep the local count of people on each floor. Floor are uniquely identified by building and floor number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_conf = {\n",
    "    'bootstrap.servers': brokers,\n",
    "    ## Your configuration code here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Consumer Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following dictionary to maintain aggregate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in range(0,1000):\n",
    "            # Your consuming code here\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(floors.keys(), floors.values(), color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Let's save the aggregated result in a topic and progress from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pconf = {\n",
    "    'bootstrap.servers': brokers,\n",
    "       ## Your Configuration Code Here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your producer Code Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for f in floors.keys():\n",
    "       ## Your producering Code Here \n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of people per building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_conf = {\n",
    "    'bootstrap.servers': brokers,\n",
    "   ## Your configuration Code Here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your consumer Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in range(1,1000):\n",
    "         ## Your consuming Code Here\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(buildings.keys(), buildings.values(), color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the dataflow between topic using a tool of choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://placehold.it/256x256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Tasks (but useful for preparing the final examm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Add a 1 minute window to the aggreagtion (see wordcount example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 Redo Task 0-3 modelling observations using AVRO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
