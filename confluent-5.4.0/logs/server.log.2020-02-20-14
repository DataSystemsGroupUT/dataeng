[2020-02-20 14:00:41,096] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 5 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 10 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 42 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 24 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 37 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 25 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 14 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 20 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 46 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 29 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 6 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 28 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 38 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 21 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 33 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 9 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 13 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 41 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 32 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 34 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 45 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 17 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 22 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 44 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 27 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 12 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 49 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 7 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 39 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 35 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 48 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 18 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 16 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 31 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 11 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 43 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 40 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 26 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 23 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 8 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 36 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 30 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 19 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 47 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None), 15 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:00:41,102] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-20 14:00:41,192] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:00:41,196] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,197] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,197] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,198] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,198] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,199] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,199] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,199] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,203] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,204] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 3 ms (kafka.log.Log)
[2020-02-20 14:00:41,204] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,204] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,205] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,205] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-02-20 14:00:41,205] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,205] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,209] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,212] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 5 ms (kafka.log.Log)
[2020-02-20 14:00:41,213] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,213] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,214] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,214] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-02-20 14:00:41,214] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,214] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,218] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,219] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,219] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,219] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,220] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,220] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-02-20 14:00:41,220] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,220] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,225] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,225] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 3 ms (kafka.log.Log)
[2020-02-20 14:00:41,226] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,227] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,227] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,227] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-02-20 14:00:41,227] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,228] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,231] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,232] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,232] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,232] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,233] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,233] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-02-20 14:00:41,233] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,233] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,237] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,238] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 3 ms (kafka.log.Log)
[2020-02-20 14:00:41,238] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,238] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,239] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,239] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-02-20 14:00:41,239] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,239] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,243] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,243] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,243] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,244] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,244] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,245] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-02-20 14:00:41,245] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,245] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,248] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,249] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,249] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,250] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,251] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,251] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-02-20 14:00:41,251] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,251] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,255] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,256] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 3 ms (kafka.log.Log)
[2020-02-20 14:00:41,256] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,257] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,257] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,257] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-02-20 14:00:41,257] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,257] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,260] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,261] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,261] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,262] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,262] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,262] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,262] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,262] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,266] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,266] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:41,266] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,267] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,267] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,267] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-02-20 14:00:41,267] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,267] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,270] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,271] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,271] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,272] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,272] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,272] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-02-20 14:00:41,272] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,272] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,275] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,276] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,276] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,277] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,277] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:41,277] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-02-20 14:00:41,277] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:41,278] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:41,281] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,281] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:41,281] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:41,282] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:41,282] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,257] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-02-20 14:00:42,257] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,258] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,263] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,263] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,263] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,264] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,264] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,265] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-02-20 14:00:42,265] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,265] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,268] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,268] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,268] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,269] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,269] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,270] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-02-20 14:00:42,270] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,270] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,272] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,273] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,273] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,273] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,274] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,274] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-02-20 14:00:42,274] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,274] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,277] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,278] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,278] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,278] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,279] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,279] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-02-20 14:00:42,279] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,279] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,282] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,282] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,283] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,283] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,283] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,284] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-02-20 14:00:42,284] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,284] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,286] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,287] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,287] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,287] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,288] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,288] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-02-20 14:00:42,288] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,288] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,291] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,291] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,291] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,292] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,292] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,292] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-02-20 14:00:42,292] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,292] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,295] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,296] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,296] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,297] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,297] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,297] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-02-20 14:00:42,297] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,297] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,300] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,301] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,301] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,301] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,302] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,302] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-02-20 14:00:42,302] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,302] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,304] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,305] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,305] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,305] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,306] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,306] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-02-20 14:00:42,306] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,306] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,309] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,309] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,309] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,309] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,310] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,310] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-02-20 14:00:42,310] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,310] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,313] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,313] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,313] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,314] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,314] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,314] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-02-20 14:00:42,314] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,315] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,317] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,318] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,318] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,318] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,318] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,318] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-02-20 14:00:42,319] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,319] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,321] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,322] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,322] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,322] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,323] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,323] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-02-20 14:00:42,323] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,323] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,325] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,326] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,326] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,326] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,327] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,327] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-02-20 14:00:42,327] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,327] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,330] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,330] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,330] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,331] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,331] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,331] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-02-20 14:00:42,331] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,331] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,334] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,334] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,334] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,335] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,335] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,335] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-02-20 14:00:42,335] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,335] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,338] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,339] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,339] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,339] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,339] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,339] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-02-20 14:00:42,340] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,340] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,342] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,343] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,343] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,343] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,344] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,344] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-02-20 14:00:42,344] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,344] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,347] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,347] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,347] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,348] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,348] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,348] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-02-20 14:00:42,348] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,348] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,351] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,351] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,351] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,352] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,352] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,352] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-02-20 14:00:42,352] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,352] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,354] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,355] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,355] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,355] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,356] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,356] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-02-20 14:00:42,356] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,356] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,358] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,358] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,358] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,359] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,359] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,359] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-02-20 14:00:42,359] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,359] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,362] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,362] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,362] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,363] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,363] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,363] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-02-20 14:00:42,363] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,363] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,366] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,366] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,366] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,367] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,367] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,367] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-02-20 14:00:42,367] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,367] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,370] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,370] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,370] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,371] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,371] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,371] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-02-20 14:00:42,371] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,371] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,374] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,381] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-20 14:00:42,381] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,381] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,382] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,382] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-02-20 14:00:42,382] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,382] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,385] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,385] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,385] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,385] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,386] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,386] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-02-20 14:00:42,386] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,386] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,389] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,389] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,389] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,389] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,390] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,390] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-02-20 14:00:42,390] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,390] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,392] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,393] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:00:42,393] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,393] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,394] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,394] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-02-20 14:00:42,394] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,394] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,397] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,397] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,397] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,398] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,398] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,398] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-02-20 14:00:42,398] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,398] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,401] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,401] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,401] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,402] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,402] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,402] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-02-20 14:00:42,402] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,402] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,405] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,405] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,405] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,406] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,406] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,406] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-02-20 14:00:42,406] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,406] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,409] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,409] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,409] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,410] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,410] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,410] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-02-20 14:00:42,410] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,410] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,413] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,413] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:00:42,413] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:00:42,413] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:00:42,414] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:00:42,414] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-02-20 14:00:42,414] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:00:42,414] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:00:42,416] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,419] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,419] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,419] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,420] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:00:42,507] INFO [GroupCoordinator 0]: Preparing to rebalance group numbers in state PreparingRebalance with old generation 0 (__consumer_offsets-10) (reason: Adding new member numbers-84df22aa-fc40-44b3-81ca-1a1d9d1c9786-StreamThread-1-consumer-a18a69fd-81ad-4a58-8de0-e526b15c298c with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:00:42,513] INFO [GroupCoordinator 0]: Stabilized group numbers generation 1 (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:00:42,523] INFO [GroupCoordinator 0]: Assignment received from leader for group numbers for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:00:58,542] INFO [GroupCoordinator 0]: Member numbers-84df22aa-fc40-44b3-81ca-1a1d9d1c9786-StreamThread-1-consumer-a18a69fd-81ad-4a58-8de0-e526b15c298c in group numbers has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:00:58,543] INFO [GroupCoordinator 0]: Preparing to rebalance group numbers in state PreparingRebalance with old generation 1 (__consumer_offsets-10) (reason: removing member numbers-84df22aa-fc40-44b3-81ca-1a1d9d1c9786-StreamThread-1-consumer-a18a69fd-81ad-4a58-8de0-e526b15c298c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:00:58,544] INFO [GroupCoordinator 0]: Group numbers with generation 2 is now empty (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:02:10,051] INFO [GroupMetadataManager brokerId=0] Group numbers transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:02:10,054] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:02:53,407] INFO [GroupCoordinator 0]: Preparing to rebalance group c2541968-a4c6-4c96-92e6-4c38f3dd7977 in state PreparingRebalance with old generation 0 (__consumer_offsets-43) (reason: Adding new member c2541968-a4c6-4c96-92e6-4c38f3dd7977-f13e1bdd-3b60-44c2-829c-b0360a7b3533-StreamThread-1-consumer-6d1b7011-157d-44f4-b697-44c79309875c with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:02:53,408] INFO [GroupCoordinator 0]: Stabilized group c2541968-a4c6-4c96-92e6-4c38f3dd7977 generation 1 (__consumer_offsets-43) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:02:53,419] INFO [GroupCoordinator 0]: Assignment received from leader for group c2541968-a4c6-4c96-92e6-4c38f3dd7977 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:04:56,621] INFO [GroupCoordinator 0]: Preparing to rebalance group e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb-51b90e62-3618-40c8-9226-73513e389ebd-StreamThread-1-consumer-a3a1c59f-9899-4e46-90b8-f9e84b4109f2 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:04:56,622] INFO [GroupCoordinator 0]: Stabilized group e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:04:56,631] INFO [GroupCoordinator 0]: Assignment received from leader for group e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:04:56,696] INFO Creating topic odds with configuration {} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:04:56,698] INFO [KafkaApi-0] Auto creation of topic odds with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-20 14:04:56,703] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(odds-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:04:56,705] INFO [Log partition=odds-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:04:56,706] INFO [Log partition=odds-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:04:56,706] INFO [Log partition=odds-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:04:56,706] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:04:56,707] INFO Created log for partition odds-0 in /tmp/kafka-logs/odds-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:04:56,707] INFO [Partition odds-0 broker=0] No checkpointed highwatermark is found for partition odds-0 (kafka.cluster.Partition)
[2020-02-20 14:04:56,707] INFO [Partition odds-0 broker=0] Log loaded for partition odds-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:04:56,707] INFO [Partition odds-0 broker=0] odds-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:05:03,663] INFO [GroupCoordinator 0]: Member c2541968-a4c6-4c96-92e6-4c38f3dd7977-f13e1bdd-3b60-44c2-829c-b0360a7b3533-StreamThread-1-consumer-6d1b7011-157d-44f4-b697-44c79309875c in group c2541968-a4c6-4c96-92e6-4c38f3dd7977 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:05:03,664] INFO [GroupCoordinator 0]: Preparing to rebalance group c2541968-a4c6-4c96-92e6-4c38f3dd7977 in state PreparingRebalance with old generation 1 (__consumer_offsets-43) (reason: removing member c2541968-a4c6-4c96-92e6-4c38f3dd7977-f13e1bdd-3b60-44c2-829c-b0360a7b3533-StreamThread-1-consumer-6d1b7011-157d-44f4-b697-44c79309875c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:05:03,664] INFO [GroupCoordinator 0]: Group c2541968-a4c6-4c96-92e6-4c38f3dd7977 with generation 2 is now empty (__consumer_offsets-43) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:05:42,514] INFO [GroupCoordinator 0]: Received notification of heartbeat expiration for member numbers-84df22aa-fc40-44b3-81ca-1a1d9d1c9786-StreamThread-1-consumer-a18a69fd-81ad-4a58-8de0-e526b15c298c after group numbers had already been unloaded or deleted. (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:09,856] INFO [GroupCoordinator 0]: Member e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb-51b90e62-3618-40c8-9226-73513e389ebd-StreamThread-1-consumer-a3a1c59f-9899-4e46-90b8-f9e84b4109f2 in group e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:09,856] INFO [GroupCoordinator 0]: Preparing to rebalance group e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: removing member e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb-51b90e62-3618-40c8-9226-73513e389ebd-StreamThread-1-consumer-a3a1c59f-9899-4e46-90b8-f9e84b4109f2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:09,856] INFO [GroupCoordinator 0]: Group e5a0148a-85d0-42ef-9a6c-9f51ae7c8cdb with generation 2 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:10,642] INFO [GroupCoordinator 0]: Preparing to rebalance group 95a2984a-bcb2-4275-aa5b-50a51c3e1d47 in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member 95a2984a-bcb2-4275-aa5b-50a51c3e1d47-641ac15e-ebbd-4008-9766-87d09a392bfd-StreamThread-1-consumer-c8be32d4-4a5e-422e-9bfd-b7f40566d2e6 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:10,642] INFO [GroupCoordinator 0]: Stabilized group 95a2984a-bcb2-4275-aa5b-50a51c3e1d47 generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:10,648] INFO [GroupCoordinator 0]: Assignment received from leader for group 95a2984a-bcb2-4275-aa5b-50a51c3e1d47 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:10,709] INFO Creating topic module2 with configuration {} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:10:10,711] INFO [KafkaApi-0] Auto creation of topic module2 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-20 14:10:10,716] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(module2-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:10:10,718] INFO [Log partition=module2-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:10:10,718] INFO [Log partition=module2-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:10:10,718] INFO [Log partition=module2-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:10:10,719] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:10:10,719] INFO Created log for partition module2-0 in /tmp/kafka-logs/module2-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:10:10,720] INFO [Partition module2-0 broker=0] No checkpointed highwatermark is found for partition module2-0 (kafka.cluster.Partition)
[2020-02-20 14:10:10,720] INFO [Partition module2-0 broker=0] Log loaded for partition module2-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:10:10,720] INFO [Partition module2-0 broker=0] module2-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:10:29,662] INFO [GroupCoordinator 0]: Member 95a2984a-bcb2-4275-aa5b-50a51c3e1d47-641ac15e-ebbd-4008-9766-87d09a392bfd-StreamThread-1-consumer-c8be32d4-4a5e-422e-9bfd-b7f40566d2e6 in group 95a2984a-bcb2-4275-aa5b-50a51c3e1d47 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:29,663] INFO [GroupCoordinator 0]: Preparing to rebalance group 95a2984a-bcb2-4275-aa5b-50a51c3e1d47 in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: removing member 95a2984a-bcb2-4275-aa5b-50a51c3e1d47-641ac15e-ebbd-4008-9766-87d09a392bfd-StreamThread-1-consumer-c8be32d4-4a5e-422e-9bfd-b7f40566d2e6 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:29,663] INFO [GroupCoordinator 0]: Group 95a2984a-bcb2-4275-aa5b-50a51c3e1d47 with generation 2 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:43,298] INFO [GroupCoordinator 0]: Preparing to rebalance group 8fe73c2e-1983-4f85-8c4f-8f0527877b15 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member 8fe73c2e-1983-4f85-8c4f-8f0527877b15-c3b78c12-ec17-4265-a64a-f1863687beba-StreamThread-1-consumer-21857b76-db2a-4332-ab22-e94ace6885c2 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:43,299] INFO [GroupCoordinator 0]: Stabilized group 8fe73c2e-1983-4f85-8c4f-8f0527877b15 generation 1 (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:10:43,307] INFO [GroupCoordinator 0]: Assignment received from leader for group 8fe73c2e-1983-4f85-8c4f-8f0527877b15 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:13,684] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-48109 in state PreparingRebalance with old generation 0 (__consumer_offsets-23) (reason: Adding new member consumer-console-consumer-48109-1-d3382813-dd07-407e-a2e7-ffaa4bd76178 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:13,684] INFO [GroupCoordinator 0]: Stabilized group console-consumer-48109 generation 1 (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:13,687] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-48109 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:16,596] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-console-consumer-48109-1-d3382813-dd07-407e-a2e7-ffaa4bd76178] in group console-consumer-48109 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:16,596] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-48109 in state PreparingRebalance with old generation 1 (__consumer_offsets-23) (reason: removing member consumer-console-consumer-48109-1-d3382813-dd07-407e-a2e7-ffaa4bd76178 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:16,596] INFO [GroupCoordinator 0]: Group console-consumer-48109 with generation 2 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:28,695] INFO [GroupCoordinator 0]: Preparing to rebalance group consumer1 in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member consumer-1-2516d2f8-99ff-402f-b3ea-46b99449aaa9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:28,695] INFO [GroupCoordinator 0]: Stabilized group consumer1 generation 1 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:28,699] INFO [GroupCoordinator 0]: Assignment received from leader for group consumer1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:46,707] INFO [GroupCoordinator 0]: Member consumer-1-2516d2f8-99ff-402f-b3ea-46b99449aaa9 in group consumer1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:46,707] INFO [GroupCoordinator 0]: Preparing to rebalance group consumer1 in state PreparingRebalance with old generation 1 (__consumer_offsets-49) (reason: removing member consumer-1-2516d2f8-99ff-402f-b3ea-46b99449aaa9 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:11:46,707] INFO [GroupCoordinator 0]: Group consumer1 with generation 2 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:12:10,036] INFO [GroupMetadataManager brokerId=0] Group 95a2984a-bcb2-4275-aa5b-50a51c3e1d47 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:12:10,037] INFO [GroupMetadataManager brokerId=0] Group console-consumer-48109 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:12:10,039] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:13:11,297] INFO [GroupCoordinator 0]: Preparing to rebalance group d1329a64-d398-476b-9e9f-0320d51534d1 in state PreparingRebalance with old generation 0 (__consumer_offsets-6) (reason: Adding new member d1329a64-d398-476b-9e9f-0320d51534d1-10e3555c-0040-4965-aa9d-1ba768544878-StreamThread-1-consumer-3705421b-e36d-4ffe-b36a-3f3bee07b03c with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:13:11,297] INFO [GroupCoordinator 0]: Stabilized group d1329a64-d398-476b-9e9f-0320d51534d1 generation 1 (__consumer_offsets-6) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:13:11,312] INFO Creating topic d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:13:11,321] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:13:11,322] INFO [Log partition=d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:13:11,323] INFO [Log partition=d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:13:11,323] INFO [Log partition=d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:13:11,323] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:13:11,324] INFO Created log for partition d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 in /tmp/kafka-logs/d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:13:11,325] INFO [Partition d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 broker=0] No checkpointed highwatermark is found for partition d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:13:11,325] INFO [Partition d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 broker=0] Log loaded for partition d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:13:11,325] INFO [Partition d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 broker=0] d1329a64-d398-476b-9e9f-0320d51534d1-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:13:11,335] INFO [GroupCoordinator 0]: Assignment received from leader for group d1329a64-d398-476b-9e9f-0320d51534d1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:15:10,650] INFO [GroupCoordinator 0]: Received notification of heartbeat expiration for member 95a2984a-bcb2-4275-aa5b-50a51c3e1d47-641ac15e-ebbd-4008-9766-87d09a392bfd-StreamThread-1-consumer-c8be32d4-4a5e-422e-9bfd-b7f40566d2e6 after group 95a2984a-bcb2-4275-aa5b-50a51c3e1d47 had already been unloaded or deleted. (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:17:18,537] INFO [GroupCoordinator 0]: Member d1329a64-d398-476b-9e9f-0320d51534d1-10e3555c-0040-4965-aa9d-1ba768544878-StreamThread-1-consumer-3705421b-e36d-4ffe-b36a-3f3bee07b03c in group d1329a64-d398-476b-9e9f-0320d51534d1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:17:18,537] INFO [GroupCoordinator 0]: Preparing to rebalance group d1329a64-d398-476b-9e9f-0320d51534d1 in state PreparingRebalance with old generation 1 (__consumer_offsets-6) (reason: removing member d1329a64-d398-476b-9e9f-0320d51534d1-10e3555c-0040-4965-aa9d-1ba768544878-StreamThread-1-consumer-3705421b-e36d-4ffe-b36a-3f3bee07b03c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:17:18,537] INFO [GroupCoordinator 0]: Group d1329a64-d398-476b-9e9f-0320d51534d1 with generation 2 is now empty (__consumer_offsets-6) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:17:20,556] INFO [GroupCoordinator 0]: Member 8fe73c2e-1983-4f85-8c4f-8f0527877b15-c3b78c12-ec17-4265-a64a-f1863687beba-StreamThread-1-consumer-21857b76-db2a-4332-ab22-e94ace6885c2 in group 8fe73c2e-1983-4f85-8c4f-8f0527877b15 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:17:20,557] INFO [GroupCoordinator 0]: Preparing to rebalance group 8fe73c2e-1983-4f85-8c4f-8f0527877b15 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: removing member 8fe73c2e-1983-4f85-8c4f-8f0527877b15-c3b78c12-ec17-4265-a64a-f1863687beba-StreamThread-1-consumer-21857b76-db2a-4332-ab22-e94ace6885c2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:17:20,557] INFO [GroupCoordinator 0]: Group 8fe73c2e-1983-4f85-8c4f-8f0527877b15 with generation 2 is now empty (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:21:22,416] INFO Creating topic pageviews with configuration {} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:21:22,418] INFO [KafkaApi-0] Auto creation of topic pageviews with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-20 14:21:22,424] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pageviews-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:21:22,426] INFO [Log partition=pageviews-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:21:22,426] INFO [Log partition=pageviews-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:21:22,426] INFO [Log partition=pageviews-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:21:22,426] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:21:22,427] INFO Created log for partition pageviews-0 in /tmp/kafka-logs/pageviews-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:21:22,428] INFO [Partition pageviews-0 broker=0] No checkpointed highwatermark is found for partition pageviews-0 (kafka.cluster.Partition)
[2020-02-20 14:21:22,428] INFO [Partition pageviews-0 broker=0] Log loaded for partition pageviews-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:21:22,428] INFO [Partition pageviews-0 broker=0] pageviews-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:22:09,378] INFO Creating topic users with configuration {} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:22:09,380] INFO [KafkaApi-0] Auto creation of topic users with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-20 14:22:09,385] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(users-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:22:09,387] INFO [Log partition=users-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:22:09,387] INFO [Log partition=users-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:22:09,388] INFO [Log partition=users-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:22:09,388] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:22:09,389] INFO Created log for partition users-0 in /tmp/kafka-logs/users-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:22:09,389] INFO [Partition users-0 broker=0] No checkpointed highwatermark is found for partition users-0 (kafka.cluster.Partition)
[2020-02-20 14:22:09,389] INFO [Partition users-0 broker=0] Log loaded for partition users-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:22:09,390] INFO [Partition users-0 broker=0] users-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:22:10,054] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:25:45,932] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pageviewsbyuser-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:25:45,934] INFO [Log partition=pageviewsbyuser-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:25:45,934] INFO [Log partition=pageviewsbyuser-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:25:45,934] INFO [Log partition=pageviewsbyuser-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:25:45,934] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:25:45,935] INFO Created log for partition pageviewsbyuser-0 in /tmp/kafka-logs/pageviewsbyuser-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:25:45,935] INFO [Partition pageviewsbyuser-0 broker=0] No checkpointed highwatermark is found for partition pageviewsbyuser-0 (kafka.cluster.Partition)
[2020-02-20 14:25:45,935] INFO [Partition pageviewsbyuser-0 broker=0] Log loaded for partition pageviewsbyuser-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:25:45,935] INFO [Partition pageviewsbyuser-0 broker=0] pageviewsbyuser-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:29:24,756] INFO [GroupCoordinator 0]: Preparing to rebalance group 0e10d35a-c732-405c-93ef-06f3fa5f0863 in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member 0e10d35a-c732-405c-93ef-06f3fa5f0863-7add8f27-b1f6-4883-a899-08f41cfdc5ab-StreamThread-1-consumer-35e89045-2ca0-4a62-9f2e-9b9d3fd4c707 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:29:24,757] INFO [GroupCoordinator 0]: Stabilized group 0e10d35a-c732-405c-93ef-06f3fa5f0863 generation 1 (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:29:24,771] INFO Creating topic 0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:29:24,779] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:29:24,781] INFO [Log partition=0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:29:24,781] INFO [Log partition=0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:29:24,781] INFO [Log partition=0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:29:24,781] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:29:24,782] INFO Created log for partition 0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0 in /tmp/kafka-logs/0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:29:24,782] INFO [Partition 0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:29:24,783] INFO [Partition 0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0 broker=0] Log loaded for partition 0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:29:24,783] INFO [Partition 0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0 broker=0] 0e10d35a-c732-405c-93ef-06f3fa5f0863-users-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:29:24,790] INFO [GroupCoordinator 0]: Assignment received from leader for group 0e10d35a-c732-405c-93ef-06f3fa5f0863 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:32:10,065] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:32:58,986] INFO [GroupCoordinator 0]: Member 0e10d35a-c732-405c-93ef-06f3fa5f0863-7add8f27-b1f6-4883-a899-08f41cfdc5ab-StreamThread-1-consumer-35e89045-2ca0-4a62-9f2e-9b9d3fd4c707 in group 0e10d35a-c732-405c-93ef-06f3fa5f0863 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:32:58,986] INFO [GroupCoordinator 0]: Preparing to rebalance group 0e10d35a-c732-405c-93ef-06f3fa5f0863 in state PreparingRebalance with old generation 1 (__consumer_offsets-19) (reason: removing member 0e10d35a-c732-405c-93ef-06f3fa5f0863-7add8f27-b1f6-4883-a899-08f41cfdc5ab-StreamThread-1-consumer-35e89045-2ca0-4a62-9f2e-9b9d3fd4c707 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:32:58,986] INFO [GroupCoordinator 0]: Group 0e10d35a-c732-405c-93ef-06f3fa5f0863 with generation 2 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:38,519] INFO [GroupCoordinator 0]: Preparing to rebalance group 0323b4ef-c979-47c6-923a-e791b1d5df4b in state PreparingRebalance with old generation 0 (__consumer_offsets-6) (reason: Adding new member 0323b4ef-c979-47c6-923a-e791b1d5df4b-c6e2f5d3-f15c-469a-a744-3b60c2af43c3-StreamThread-1-consumer-caf7c166-1b6b-4d54-94c5-c0529a18e4e6 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:38,520] INFO [GroupCoordinator 0]: Stabilized group 0323b4ef-c979-47c6-923a-e791b1d5df4b generation 1 (__consumer_offsets-6) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:38,533] INFO Creating topic 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:38:38,542] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:38:38,544] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:38,545] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:38:38,545] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:38,545] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:38:38,545] INFO Created log for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0 in /tmp/kafka-logs/0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:38:38,546] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0 broker=0] No checkpointed highwatermark is found for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0 (kafka.cluster.Partition)
[2020-02-20 14:38:38,546] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0 broker=0] Log loaded for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:38:38,546] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0 broker=0] 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:38:38,553] INFO Creating topic 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog with configuration {retention.ms=172800000, cleanup.policy=compact,delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:38:38,559] INFO Creating topic 0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:38:38,562] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:38:38,565] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:38,565] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:38:38,566] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:38,566] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:38:38,567] INFO Created log for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0 in /tmp/kafka-logs/0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 172800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:38:38,567] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0 broker=0] No checkpointed highwatermark is found for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:38:38,567] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0 broker=0] Log loaded for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:38:38,567] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0 broker=0] 0323b4ef-c979-47c6-923a-e791b1d5df4b-KSTREAM-AGGREGATE-STATE-STORE-0000000010-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:38:38,571] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:38:38,573] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:38,574] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:38:38,574] INFO [Log partition=0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:38,574] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:38:38,575] INFO Created log for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0 in /tmp/kafka-logs/0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:38:38,575] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:38:38,575] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0 broker=0] Log loaded for partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:38:38,575] INFO [Partition 0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0 broker=0] 0323b4ef-c979-47c6-923a-e791b1d5df4b-users-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:38:38,586] INFO [GroupCoordinator 0]: Assignment received from leader for group 0323b4ef-c979-47c6-923a-e791b1d5df4b for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:48,588] INFO [GroupCoordinator 0]: Member 0323b4ef-c979-47c6-923a-e791b1d5df4b-c6e2f5d3-f15c-469a-a744-3b60c2af43c3-StreamThread-1-consumer-caf7c166-1b6b-4d54-94c5-c0529a18e4e6 in group 0323b4ef-c979-47c6-923a-e791b1d5df4b has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:48,588] INFO [GroupCoordinator 0]: Preparing to rebalance group 0323b4ef-c979-47c6-923a-e791b1d5df4b in state PreparingRebalance with old generation 1 (__consumer_offsets-6) (reason: removing member 0323b4ef-c979-47c6-923a-e791b1d5df4b-c6e2f5d3-f15c-469a-a744-3b60c2af43c3-StreamThread-1-consumer-caf7c166-1b6b-4d54-94c5-c0529a18e4e6 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:48,588] INFO [GroupCoordinator 0]: Group 0323b4ef-c979-47c6-923a-e791b1d5df4b with generation 2 is now empty (__consumer_offsets-6) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:56,046] INFO [GroupCoordinator 0]: Preparing to rebalance group 4b10c6e7-5593-4e7f-abe8-cfe12b502109 in state PreparingRebalance with old generation 0 (__consumer_offsets-38) (reason: Adding new member 4b10c6e7-5593-4e7f-abe8-cfe12b502109-4ec0773c-0105-4e0d-bda7-fb2045c5178f-StreamThread-1-consumer-c29f4366-e22c-429b-9de9-0d851d4bdbc3 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:56,046] INFO [GroupCoordinator 0]: Stabilized group 4b10c6e7-5593-4e7f-abe8-cfe12b502109 generation 1 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:38:56,060] INFO Creating topic 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:38:56,068] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:38:56,071] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:56,072] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:38:56,072] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:56,073] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:38:56,074] INFO Created log for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0 in /tmp/kafka-logs/4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:38:56,074] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0 broker=0] No checkpointed highwatermark is found for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0 (kafka.cluster.Partition)
[2020-02-20 14:38:56,074] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0 broker=0] Log loaded for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:38:56,074] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0 broker=0] 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:38:56,082] INFO Creating topic 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog with configuration {retention.ms=172800000, cleanup.policy=compact,delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:38:56,088] INFO Creating topic 4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:38:56,091] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:38:56,093] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:56,094] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:38:56,094] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:56,095] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:38:56,096] INFO Created log for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0 in /tmp/kafka-logs/4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 172800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:38:56,096] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0 broker=0] No checkpointed highwatermark is found for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:38:56,096] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0 broker=0] Log loaded for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:38:56,096] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0 broker=0] 4b10c6e7-5593-4e7f-abe8-cfe12b502109-KSTREAM-AGGREGATE-STATE-STORE-0000000009-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:38:56,102] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:38:56,105] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:56,106] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:38:56,106] INFO [Log partition=4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:38:56,106] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:38:56,107] INFO Created log for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0 in /tmp/kafka-logs/4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:38:56,107] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:38:56,107] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0 broker=0] Log loaded for partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:38:56,107] INFO [Partition 4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0 broker=0] 4b10c6e7-5593-4e7f-abe8-cfe12b502109-users-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:38:56,120] INFO [GroupCoordinator 0]: Assignment received from leader for group 4b10c6e7-5593-4e7f-abe8-cfe12b502109 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:39:06,126] INFO [GroupCoordinator 0]: Member 4b10c6e7-5593-4e7f-abe8-cfe12b502109-4ec0773c-0105-4e0d-bda7-fb2045c5178f-StreamThread-1-consumer-c29f4366-e22c-429b-9de9-0d851d4bdbc3 in group 4b10c6e7-5593-4e7f-abe8-cfe12b502109 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:39:06,126] INFO [GroupCoordinator 0]: Preparing to rebalance group 4b10c6e7-5593-4e7f-abe8-cfe12b502109 in state PreparingRebalance with old generation 1 (__consumer_offsets-38) (reason: removing member 4b10c6e7-5593-4e7f-abe8-cfe12b502109-4ec0773c-0105-4e0d-bda7-fb2045c5178f-StreamThread-1-consumer-c29f4366-e22c-429b-9de9-0d851d4bdbc3 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:39:06,127] INFO [GroupCoordinator 0]: Group 4b10c6e7-5593-4e7f-abe8-cfe12b502109 with generation 2 is now empty (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:41:33,688] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pageviewsbyregion-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:41:33,690] INFO [Log partition=pageviewsbyregion-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:41:33,690] INFO [Log partition=pageviewsbyregion-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:41:33,690] INFO [Log partition=pageviewsbyregion-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:41:33,690] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:41:33,691] INFO Created log for partition pageviewsbyregion-0 in /tmp/kafka-logs/pageviewsbyregion-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:41:33,691] INFO [Partition pageviewsbyregion-0 broker=0] No checkpointed highwatermark is found for partition pageviewsbyregion-0 (kafka.cluster.Partition)
[2020-02-20 14:41:33,691] INFO [Partition pageviewsbyregion-0 broker=0] Log loaded for partition pageviewsbyregion-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:41:33,691] INFO [Partition pageviewsbyregion-0 broker=0] pageviewsbyregion-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:42:10,037] INFO [GroupMetadataManager brokerId=0] Group 4b10c6e7-5593-4e7f-abe8-cfe12b502109 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:42:10,037] INFO [GroupMetadataManager brokerId=0] Group 0323b4ef-c979-47c6-923a-e791b1d5df4b transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:42:10,038] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-20 14:42:15,711] INFO [GroupCoordinator 0]: Preparing to rebalance group 26b24a87-b1b2-4649-a932-e15fa524d1bd in state PreparingRebalance with old generation 0 (__consumer_offsets-23) (reason: Adding new member 26b24a87-b1b2-4649-a932-e15fa524d1bd-3812080c-95c5-4d43-886b-17fb0761d89a-StreamThread-1-consumer-3aab57f7-2833-4b79-b6fd-9bbbb4770abd with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:42:15,712] INFO [GroupCoordinator 0]: Stabilized group 26b24a87-b1b2-4649-a932-e15fa524d1bd generation 1 (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:42:15,725] INFO Creating topic 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:42:15,732] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:42:15,735] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:42:15,735] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 1 ms (kafka.log.Log)
[2020-02-20 14:42:15,735] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:42:15,736] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:42:15,736] INFO Created log for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0 in /tmp/kafka-logs/26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:42:15,737] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0 broker=0] No checkpointed highwatermark is found for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0 (kafka.cluster.Partition)
[2020-02-20 14:42:15,737] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0 broker=0] Log loaded for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:42:15,737] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0 broker=0] 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:42:15,744] INFO Creating topic 26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:42:15,750] INFO Creating topic 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog with configuration {retention.ms=172800000, cleanup.policy=compact,delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:42:15,753] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:42:15,755] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:42:15,756] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:42:15,756] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:42:15,757] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:42:15,757] INFO Created log for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0 in /tmp/kafka-logs/26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:42:15,758] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:42:15,758] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0 broker=0] Log loaded for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:42:15,758] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0 broker=0] 26b24a87-b1b2-4649-a932-e15fa524d1bd-users-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:42:15,761] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:42:15,764] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:42:15,764] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:42:15,764] INFO [Log partition=26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:42:15,765] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:42:15,765] INFO Created log for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 in /tmp/kafka-logs/26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 172800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:42:15,766] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 broker=0] No checkpointed highwatermark is found for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:42:15,766] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 broker=0] Log loaded for partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:42:15,766] INFO [Partition 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 broker=0] 26b24a87-b1b2-4649-a932-e15fa524d1bd-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:42:15,776] INFO [GroupCoordinator 0]: Assignment received from leader for group 26b24a87-b1b2-4649-a932-e15fa524d1bd for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:42:25,779] INFO [GroupCoordinator 0]: Member 26b24a87-b1b2-4649-a932-e15fa524d1bd-3812080c-95c5-4d43-886b-17fb0761d89a-StreamThread-1-consumer-3aab57f7-2833-4b79-b6fd-9bbbb4770abd in group 26b24a87-b1b2-4649-a932-e15fa524d1bd has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:42:25,779] INFO [GroupCoordinator 0]: Preparing to rebalance group 26b24a87-b1b2-4649-a932-e15fa524d1bd in state PreparingRebalance with old generation 1 (__consumer_offsets-23) (reason: removing member 26b24a87-b1b2-4649-a932-e15fa524d1bd-3812080c-95c5-4d43-886b-17fb0761d89a-StreamThread-1-consumer-3aab57f7-2833-4b79-b6fd-9bbbb4770abd on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:42:25,779] INFO [GroupCoordinator 0]: Group 26b24a87-b1b2-4649-a932-e15fa524d1bd with generation 2 is now empty (__consumer_offsets-23) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:43:24,429] INFO [GroupCoordinator 0]: Preparing to rebalance group 9035489f-067a-43a3-95f8-c8e1564e1aa2 in state PreparingRebalance with old generation 0 (__consumer_offsets-9) (reason: Adding new member 9035489f-067a-43a3-95f8-c8e1564e1aa2-85a0260d-5034-4cbc-bbdf-7b2958569a64-StreamThread-1-consumer-e45b196e-3d25-47df-82ae-bc7fa82027af with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:43:24,430] INFO [GroupCoordinator 0]: Stabilized group 9035489f-067a-43a3-95f8-c8e1564e1aa2 generation 1 (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:43:24,440] INFO Creating topic 9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:43:24,443] INFO Creating topic 9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog with configuration {retention.ms=172800000, cleanup.policy=compact,delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:43:24,446] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:43:24,449] INFO [Log partition=9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:43:24,450] INFO [Log partition=9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:43:24,450] INFO [Log partition=9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:43:24,450] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:43:24,451] INFO Created log for partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0 in /tmp/kafka-logs/9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:43:24,451] INFO [Partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:43:24,451] INFO [Partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0 broker=0] Log loaded for partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:43:24,451] INFO [Partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0 broker=0] 9035489f-067a-43a3-95f8-c8e1564e1aa2-users-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:43:24,454] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:43:24,457] INFO [Log partition=9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:43:24,458] INFO [Log partition=9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:43:24,458] INFO [Log partition=9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:43:24,458] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:43:24,459] INFO Created log for partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 in /tmp/kafka-logs/9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 172800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:43:24,459] INFO [Partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 broker=0] No checkpointed highwatermark is found for partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:43:24,459] INFO [Partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 broker=0] Log loaded for partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:43:24,459] INFO [Partition 9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 broker=0] 9035489f-067a-43a3-95f8-c8e1564e1aa2-KSTREAM-AGGREGATE-STATE-STORE-0000000011-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:43:24,467] INFO [GroupCoordinator 0]: Assignment received from leader for group 9035489f-067a-43a3-95f8-c8e1564e1aa2 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:43:34,471] INFO [GroupCoordinator 0]: Member 9035489f-067a-43a3-95f8-c8e1564e1aa2-85a0260d-5034-4cbc-bbdf-7b2958569a64-StreamThread-1-consumer-e45b196e-3d25-47df-82ae-bc7fa82027af in group 9035489f-067a-43a3-95f8-c8e1564e1aa2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:43:34,472] INFO [GroupCoordinator 0]: Preparing to rebalance group 9035489f-067a-43a3-95f8-c8e1564e1aa2 in state PreparingRebalance with old generation 1 (__consumer_offsets-9) (reason: removing member 9035489f-067a-43a3-95f8-c8e1564e1aa2-85a0260d-5034-4cbc-bbdf-7b2958569a64-StreamThread-1-consumer-e45b196e-3d25-47df-82ae-bc7fa82027af on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:43:34,472] INFO [GroupCoordinator 0]: Group 9035489f-067a-43a3-95f8-c8e1564e1aa2 with generation 2 is now empty (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:43:38,529] INFO [GroupCoordinator 0]: Received notification of heartbeat expiration for member 0323b4ef-c979-47c6-923a-e791b1d5df4b-c6e2f5d3-f15c-469a-a744-3b60c2af43c3-StreamThread-1-consumer-caf7c166-1b6b-4d54-94c5-c0529a18e4e6 after group 0323b4ef-c979-47c6-923a-e791b1d5df4b had already been unloaded or deleted. (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:43:56,054] INFO [GroupCoordinator 0]: Received notification of heartbeat expiration for member 4b10c6e7-5593-4e7f-abe8-cfe12b502109-4ec0773c-0105-4e0d-bda7-fb2045c5178f-StreamThread-1-consumer-c29f4366-e22c-429b-9de9-0d851d4bdbc3 after group 4b10c6e7-5593-4e7f-abe8-cfe12b502109 had already been unloaded or deleted. (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:44:10,035] INFO [GroupCoordinator 0]: Preparing to rebalance group 5e340676-9c40-4910-9f92-463fff6ccced in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member 5e340676-9c40-4910-9f92-463fff6ccced-ca5d7a9e-f12e-46c9-8c52-1a408fd3a045-StreamThread-1-consumer-637dc9b1-a2fb-462f-8ef2-3b61b45792ea with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:44:10,036] INFO [GroupCoordinator 0]: Stabilized group 5e340676-9c40-4910-9f92-463fff6ccced generation 1 (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:44:10,052] INFO Creating topic 5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:44:10,058] INFO Creating topic 5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog with configuration {retention.ms=172800000, cleanup.policy=compact,delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:44:10,069] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:44:10,073] INFO [Log partition=5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:44:10,074] INFO [Log partition=5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 3 ms (kafka.log.Log)
[2020-02-20 14:44:10,074] INFO [Log partition=5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:44:10,075] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:44:10,075] INFO Created log for partition 5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0 in /tmp/kafka-logs/5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:44:10,078] INFO [Partition 5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:44:10,078] INFO [Partition 5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0 broker=0] Log loaded for partition 5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:44:10,078] INFO [Partition 5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0 broker=0] 5e340676-9c40-4910-9f92-463fff6ccced-users-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:44:10,082] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:44:10,085] INFO [Log partition=5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:44:10,086] INFO [Log partition=5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:44:10,086] INFO [Log partition=5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:44:10,087] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:44:10,087] INFO Created log for partition 5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 in /tmp/kafka-logs/5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 172800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:44:10,088] INFO [Partition 5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 broker=0] No checkpointed highwatermark is found for partition 5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:44:10,088] INFO [Partition 5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 broker=0] Log loaded for partition 5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:44:10,088] INFO [Partition 5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 broker=0] 5e340676-9c40-4910-9f92-463fff6ccced-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:44:10,097] INFO [GroupCoordinator 0]: Assignment received from leader for group 5e340676-9c40-4910-9f92-463fff6ccced for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:44:20,099] INFO [GroupCoordinator 0]: Member 5e340676-9c40-4910-9f92-463fff6ccced-ca5d7a9e-f12e-46c9-8c52-1a408fd3a045-StreamThread-1-consumer-637dc9b1-a2fb-462f-8ef2-3b61b45792ea in group 5e340676-9c40-4910-9f92-463fff6ccced has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:44:20,100] INFO [GroupCoordinator 0]: Preparing to rebalance group 5e340676-9c40-4910-9f92-463fff6ccced in state PreparingRebalance with old generation 1 (__consumer_offsets-19) (reason: removing member 5e340676-9c40-4910-9f92-463fff6ccced-ca5d7a9e-f12e-46c9-8c52-1a408fd3a045-StreamThread-1-consumer-637dc9b1-a2fb-462f-8ef2-3b61b45792ea on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:44:20,100] INFO [GroupCoordinator 0]: Group 5e340676-9c40-4910-9f92-463fff6ccced with generation 2 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:45:02,965] INFO [GroupCoordinator 0]: Preparing to rebalance group 5ae4b053-0862-4968-a83b-371ba2e80cdf in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member 5ae4b053-0862-4968-a83b-371ba2e80cdf-e65ef103-3800-465d-a3a9-28d6eb975ef9-StreamThread-1-consumer-c39b9845-0118-4899-adc8-6e2eb82f6314 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:45:02,965] INFO [GroupCoordinator 0]: Stabilized group 5ae4b053-0862-4968-a83b-371ba2e80cdf generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:45:02,979] INFO Creating topic 5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog with configuration {retention.ms=172800000, cleanup.policy=compact,delete} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:45:02,984] INFO Creating topic 5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=, observers=, targetObservers=None)) (kafka.zk.AdminZkClient)
[2020-02-20 14:45:02,988] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:45:02,990] INFO [Log partition=5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:45:02,991] INFO [Log partition=5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:45:02,991] INFO [Log partition=5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:45:02,992] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:45:02,992] INFO Created log for partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 in /tmp/kafka-logs/5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 172800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:45:02,998] INFO [Partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 broker=0] No checkpointed highwatermark is found for partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:45:02,998] INFO [Partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 broker=0] Log loaded for partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:45:02,998] INFO [Partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 broker=0] 5ae4b053-0862-4968-a83b-371ba2e80cdf-KSTREAM-AGGREGATE-STATE-STORE-0000000012-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:45:03,001] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-02-20 14:45:03,002] INFO [Log partition=5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:45:03,003] INFO [Log partition=5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset (merged: 0, local: 0) and log end offset 0 in 2 ms (kafka.log.Log)
[2020-02-20 14:45:03,003] INFO [Log partition=5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-20 14:45:03,003] INFO Completed load of log with 1 segments containing 1 local segments and 0 tiered segments, tier start offset 0, first untiered offset 0, local start offset 0, log end offset 0 (kafka.log.MergedLog)
[2020-02-20 14:45:03,004] INFO Created log for partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0 in /tmp/kafka-logs/5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, confluent.missing.id.cache.ttl.sec -> 60, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, confluent.tier.local.hotset.ms -> 86400000, confluent.tier.local.hotset.bytes -> -1, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, confluent.append.record.interceptor.classes -> [], confluent.tier.enable -> false, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, confluent.schema.registry.max.cache.size -> 10000, unclean.leader.election.enable -> false, confluent.missing.id.query.range -> 200, retention.bytes -> -1, delete.retention.ms -> 86400000, confluent.schema.registry.max.retries -> 1, segment.ms -> 604800000, confluent.schema.registry.retries.wait.ms -> 0, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-02-20 14:45:03,004] INFO [Partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0 broker=0] No checkpointed highwatermark is found for partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0 (kafka.cluster.Partition)
[2020-02-20 14:45:03,004] INFO [Partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0 broker=0] Log loaded for partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-02-20 14:45:03,004] INFO [Partition 5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0 broker=0] 5ae4b053-0862-4968-a83b-371ba2e80cdf-users-STATE-STORE-0000000004-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-20 14:45:03,012] INFO [GroupCoordinator 0]: Assignment received from leader for group 5ae4b053-0862-4968-a83b-371ba2e80cdf for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:45:13,016] INFO [GroupCoordinator 0]: Member 5ae4b053-0862-4968-a83b-371ba2e80cdf-e65ef103-3800-465d-a3a9-28d6eb975ef9-StreamThread-1-consumer-c39b9845-0118-4899-adc8-6e2eb82f6314 in group 5ae4b053-0862-4968-a83b-371ba2e80cdf has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:45:13,016] INFO [GroupCoordinator 0]: Preparing to rebalance group 5ae4b053-0862-4968-a83b-371ba2e80cdf in state PreparingRebalance with old generation 1 (__consumer_offsets-16) (reason: removing member 5ae4b053-0862-4968-a83b-371ba2e80cdf-e65ef103-3800-465d-a3a9-28d6eb975ef9-StreamThread-1-consumer-c39b9845-0118-4899-adc8-6e2eb82f6314 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-20 14:45:13,016] INFO [GroupCoordinator 0]: Group 5ae4b053-0862-4968-a83b-371ba2e80cdf with generation 2 is now empty (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
