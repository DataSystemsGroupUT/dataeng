{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Starting_file-dataEng-data_augmentation.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb","timestamp":1597339101093}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4EFY9e5wRn7v"},"source":["##### Copyright 2020 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"pkTRazeVRwDe","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VyOckJu6Rs-i"},"source":["# Data augmentation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0HEsULqDR7AH"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/data_augmentation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/data_augmentation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PxIOE5RnSQtj"},"source":["## Overview\n","\n","This tutorial demonstrates data augmentation: a technique to increase the diversity of your training set by applying random (but realistic) transformations such as image rotation. You will learn how to apply data augmentation in two ways. First, you will use [Keras Preprocessing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/). Next, you will use `tf.image`."]},{"cell_type":"markdown","metadata":{"id":"JBLmC4JEAABD","colab_type":"text"},"source":["Before diving to the exercise, why do you think data augmentation may be helpful for you model and when to use it?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-UxHAqXmSXN5"},"source":["## Setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jGIrHH4P013K","colab":{}},"source":["!pip install tf-nightly"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C2Q5rPenTAJP","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.datasets import mnist"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ydx3SSoF4wpG"},"source":["## Download a dataset\n","\n","This tutorial uses the [tf_flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers) dataset. For convenience, download the dataset using [TensorFlow Datasets](https://www.tensorflow.org/datasets). If you would like to learn about others ways of importing data, see the [load images](https://www.tensorflow.org/tutorials/load_data/images) tutorial.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ytHhsYmO52zy","colab":{}},"source":["(train_ds, val_ds, test_ds), metadata = tfds.load(\n","    'tf_flowers',\n","    split=['train[---]', 'train[---:---]', 'train[---]'], # assign the first 80% of train part to train_ds, the next 10% to val_ds, and the last 10% to test_ds\n","    with_info=True,\n","    as_supervised=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MjxEJtCwsnmm"},"source":["The flowers dataset has five classes."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wKwx7vQuspxz","colab":{}},"source":["num_classes = metadata.features['label'].num_classes \n","# print the number of flowers' classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zZAQW44949uw"},"source":["Let's retrieve an image from the dataset and use it to demonstrate data augmentation."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kXlx1lCr5Bip","colab":{}},"source":["get_label_name = metadata.features['label'].int2str\n","\n","image, label = next(iter(train_ds))\n","title = get_label_name(label)\n","\n","# plot 'image' and entitle your plot with image's label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vdJ6XA4q2nqK"},"source":["## Use Keras preprocessing layers"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5BTGz5AQ9LcD"},"source":["Note: The [Keras Preprocesing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing) introduced in this section are currently experimental."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GRMPnfzBB2hw"},"source":["### Resizing and rescaling\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jhG7gSWmUMJx"},"source":["You can use preprocessing layers to [resize](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Resizing) your images to a consistent shape, and to [rescale](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling) pixel values."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jMM3b85e3yhd","colab":{}},"source":["IMG_SIZE = 180\n","\n","resize_and_rescale = tf.keras.Sequential([\n","  layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n","  layers.experimental.preprocessing.Rescaling(1./255)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4z8AV1WgnYNW"},"source":["Note: the rescaling layer above standardizes pixel values to `[0,1]`. If instead you wanted `[-1,1]`, you would write `Rescaling(1./127.5, offset=-1)`.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MQiTwsHJDHAD"},"source":["You can see the result of applying these layers to an image. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X9OLuR1bC1Pd","colab":{}},"source":["result = resize_and_rescale(image)\n","# plot the result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yxAMg8Zql5lw"},"source":["You can verify the pixels are in `[0-1]`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DPTB8IQmSeKM","colab":{}},"source":["print(\"Min and max pixel values:\", result.numpy().min(), result.numpy().max())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fL6M7fuivAw4"},"source":["### Data augmentation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SL4Suj46ScfU"},"source":["You can use preprocessing layers for data augmentation as well."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V-4PugTE-4sl"},"source":["Let's create a few preprocessing layers and apply them repeatedly to the same image."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Svu_5yfa_Jb7","colab":{}},"source":["data_augmentation = tf.keras.Sequential([\n","  # include RandomFlip layers from layers.experimental.preprocessing to apply horizontal and vertical flips.\n","\n","  # include RandomRotation from layers.experimental.preprocessing to perform rotations with random angle from the range [-0.2 * 2 * pi : 0.2 * 2 * pi]\n","\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kfzEuaNg69iU","colab":{}},"source":["# Add the image to a batch\n","image = tf.expand_dims(image, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eR4wwi5Q_UZK","colab":{}},"source":["plt.figure(figsize=(10, 10))\n","for i in range(9):\n","  augmented_image = data_augmentation(image)\n","  ax = plt.subplot(3, 3, i + 1)\n","  plt.imshow(augmented_image[0])\n","  plt.axis(\"off\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DeXUnsjVXbs6","colab_type":"text"},"source":["Rerun the previous cell again and answer the following questions:\n","1. Did you get the same 9 images or not?\n","2. If they are different, then why?\n","3. Do you think it is better to apply the same (fixed) transformation to every image? "]},{"cell_type":"markdown","metadata":{"id":"FzOos2p1YhPp","colab_type":"text"},"source":["Answer:\n","\n","A1:\n","\n","A2:\n","\n","A3:\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jA17pEeS_2_-"},"source":["There are a variety of preprocessing [layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing) you can use for data augmentation including `layers.RandomContrast`, `layers.RandomCrop`, `layers.RandomZoom`, and others."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GG5RhIJtE0ng"},"source":["### Two options to use the preprocessing layers\n","\n","There are two ways you can use these preprocessing layers, with important tradeoffs."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MxGvUT727Po6"},"source":["#### Option 1: Make the preprocessing layers part of your model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ULGJQjP6hHvu","colab":{}},"source":["model = tf.keras.Sequential([\n","  resize_and_rescale,\n","  data_augmentation,\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  # Rest of your model\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pc6ELneyhJN9"},"source":["There are two important points to be aware of in this case:\n","\n","* Data augmentation will run on-device, synchronously with the rest of your layers, and benefit from GPU acceleration.\n","\n","* When you export your model using `model.save`, the preprocessing layers will be saved along with the rest of your model. If you later deploy this model, it will automatically standardize images (according to the configuration of your layers). This can save you from the effort of having to reimplement that logic server-side."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"syZwDSpiRXZP"},"source":["Note: Data augmentation is inactive at test time so input images will only be augmented during calls to `model.fit` (not `model.evaluate` or `model.predict`)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B2X3JTeY_vfv"},"source":["#### Option 2: Apply the preprocessing layers to your dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"r1Bt7w5VhVDY","colab":{}},"source":["aug_ds = train_ds.map(\n","  lambda x, y: (resize_and_rescale(x, training=True), y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HKqeahG2hVdV"},"source":["With this approach, you use `Dataset.map` to create a dataset that yields batches of augmented images. In this case:\n","\n","* Data augmentation will happen asynchronously on the CPU, and is non-blocking. You can overlap the training of your model on the GPU with data preprocessing, using `Dataset.prefetch`, shown below.\n","* In this case the prepreprocessing layers will not be exported with the model when you call `model.save`. You will need to attach them to your model before saving it or reimplement them server-side. After training, you can attach the preprocessing layers before export.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cgj51k9J7jfc"},"source":["You can find an example of the first option in the [image classification](https://www.tensorflow.org/tutorials/images/classification) tutorial. Let's demonstrate the second option here."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"31YwMQdrXKBP"},"source":["### Apply the preprocessing layers to the datasets"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WUgW-2LOGiOT"},"source":["Configure the train, validation, and test datasets with the preprocessing layers you created above. You will also configure the datasets for performance, using parallel reads and buffered prefetching to yield batches from disk without I/O become blocking. You can learn more dataset performance in the [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance) guide. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R5fGVMqlFxF7","colab":{}},"source":["batch_size = 32\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","def prepare(ds, shuffle=False, augment=False):\n","  # Resize and rescale all datasets\n","  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n","              num_parallel_calls=AUTOTUNE)\n","\n","  if shuffle:\n","    ds = ds.shuffle(1000)\n","\n","  # Batch all datasets\n","  ds = ds.batch(batch_size)\n","\n","  # Use data augmentation only on the training set\n","  if augment:\n","    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n","                num_parallel_calls=AUTOTUNE)\n","\n","  # Use buffered prefecting on all datasets\n","  return ds.prefetch(buffer_size=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mjm2zdqDzdFF","colab_type":"text"},"source":["Now, Prepare the three splits, i.e. training, validation and testing splits."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N86SFGMBHcx-","colab":{}},"source":["train_ds = prepare(train_ds, ---. ---)\n","val_ds = prepare(val_ds, ---. ---)\n","test_ds = prepare(test_ds, ---, ---)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G9NkAw_U0Hha","colab_type":"text"},"source":["For which splits you shuffled and augmented the data and why?\n","In other words, is it necessary "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9gplDz4ZV6kk"},"source":["### Train a model\n","\n","For completeness, you will now train a model using these datasets. This model has not been tuned for accuracy (the goal is to show you the mechanics)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IODSymGhq9N6","colab":{}},"source":["model = tf.keras.Sequential([\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(num_classes)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LsNsF1Qt6Xe8","colab_type":"text"},"source":["Using your own words, explain the following functions shortly:\n","\n","Conv2D:\n","\n","MaxPooling2D:\n","\n","Flatten:\n","\n","Dense:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZnRJr95WY68k","colab":{}},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7V0k9Qn7PA4","colab_type":"text"},"source":["what is an optimizer, loss [function], and [performance] metric ?\n","\n","Answer:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i_sDl9uZY9Mh","colab":{}},"source":["epochs=10\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EfSj84Mz8boV","colab_type":"text"},"source":["what is an epoch and how is it different from an iteration?\n","\n","Answer:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V9PSf4qgiQJG","colab":{}},"source":["loss, acc = model.evaluate(test_ds)\n","print(\"Accuracy\", acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0BkRvvsXb6SI"},"source":["### Custom data augmentation\n","\n","You can also create custom data augmenation layers. This tutorial shows two ways of doing so. First, you will create a `layers.Lambda` layer. This is a good way to write concise code. Next, you will write a new layer via [subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models), which gives you more control. Both layers will randomly invert the colors in an image, accoring to some probability. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nMxEhIVXmAH0","colab":{}},"source":["# Implement random_invert_img to randomly invert the input image with probability of 0.5.\n","def random_invert_img(x, p=0.5):\n","  # YOU CODE GOES HERE\n","  \n","  # END OF YOUR CODE\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C0huNpxdmDKu","colab":{}},"source":["def random_invert(factor=0.5):\n","  return layers.Lambda(lambda x: random_invert_img(x, factor))\n","\n","random_invert = random_invert()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wAcOluP0TNG6","colab":{}},"source":["plt.figure(figsize=(10, 10))\n","for i in range(9):\n","  augmented_image = random_invert(image)\n","  ax = plt.subplot(3, 3, i + 1)\n","  plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n","  plt.axis(\"off\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xd9XG2PLM5ZJ"},"source":["Next, implement a custom layer by [subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d11eExc-Ke-7","colab":{}},"source":["class RandomInvert(layers.Layer):\n","  def __init__(self, factor=0.5, **kwargs):\n","    super().__init__(**kwargs)\n","    self.factor = factor\n","\n","  def call(self, x):\n","    return random_invert_img(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qX-VQgkRL6fc","colab":{}},"source":["_ = plt.imshow(RandomInvert()(image)[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B0nmllnXZO6T"},"source":["Both of these layers can be used as described in options 1 and 2 above."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j7-k__2dAfX6"},"source":["## Using tf.image"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NJco2x35EAMs"},"source":["The above `layers.preprocessing` utilities are convenient. For finer control, you can write your own data augmentation pipelines or layers using `tf.data` and `tf.image`. You may also want to check out [TensorFlow Addons Image: Operations](https://www.tensorflow.org/addons/tutorials/image_ops) and [TensorFlow I/O: Color Space Conversions](https://www.tensorflow.org/io/tutorials/colorspace)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xR1RvjYkdd_i"},"source":["Since the flowers dataset was previously configured with data augmentation, let's reimport it to start fresh."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JB-lAS0z9ZJY","colab":{}},"source":["(train_ds, val_ds, test_ds), metadata = tfds.load(\n","    'tf_flowers',\n","    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n","    with_info=True,\n","    as_supervised=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rQ3pqBTS9hNj"},"source":["Retrieve an image to work with."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dDsPaAi8de_j","colab":{}},"source":["image, label = next(iter(train_ds))\n","_ = plt.imshow(image)\n","_ = plt.title(get_label_name(label))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"chelxcPtFiTF"},"source":["Let's use the following function to visualize and compare the original and augmented images side-by-side."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sN1ykjJCHikc","colab":{}},"source":["def visualize(original, augmented):\n","  fig = plt.figure()\n","  plt.subplot(1,2,1)\n","  plt.title('Original image')\n","  plt.imshow(original)\n","\n","  plt.subplot(1,2,2)\n","  plt.title('Augmented image')\n","  plt.imshow(augmented)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"C5X4ijQYHmlt"},"source":["### Data augmentation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RRD9oujLHo6c"},"source":["### Flipping the image\n","\n","Flip the image either vertically or horizontally."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1ZjVI24nIH0S","colab":{}},"source":["flipped = tf.image.flip_left_right(image)\n","visualize(image, flipped)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6iD_lLibIL9q"},"source":["### Grayscale the image\n","\n","Grayscale an image."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ikaMj0guIRtL","colab":{}},"source":["grayscaled = tf.image.rgb_to_grayscale(image)\n","visualize(image, tf.squeeze(grayscaled))\n","_ = plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"f-5yjIs4IZ7v"},"source":["### Saturate the image\n","\n","Saturate an image by providing a saturation factor."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PHz-NosiInmz","colab":{}},"source":["saturated = tf.image.adjust_saturation(image, 3)\n","visualize(image, saturated)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FWXiy8qfIqdC"},"source":["### Change image brightness\n","\n","Change the brightness of image by providing a brightness factor."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1hdG-j46I0nJ","colab":{}},"source":["bright = tf.image.adjust_brightness(image, 0.4)\n","visualize(image, bright)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vjEOFEITJOr2"},"source":["### Center crop the image\n","\n","Crop the image from center up to the image part you desire."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RWkK5GFHJUKT","colab":{}},"source":["cropped = tf.image.central_crop(image, central_fraction=0.5)\n","visualize(image,cropped)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"unt76GebI3Gc"},"source":["### Rotate the image\n","\n","Rotate an image by 90 degrees."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"b19KuAhkJKR-","colab":{}},"source":["rotated = tf.image.rot90(image)\n","visualize(image, rotated)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"isrM-MZtpxTq"},"source":["### Apply augmentation to a dataset\n","\n","As before, apply data augmentation to a dataset using `Dataset.map`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1JKmx06lfcFr","colab":{}},"source":["def resize_and_rescale(image, label):\n","  image = tf.cast(image, tf.float32)\n","  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n","  image = (image / 255.0)\n","  return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FvuNMF8qqRsD","colab":{}},"source":["def augment(image,label):\n","  image, label = resize_and_rescale(image, label)\n","  # Add 6 pixels of padding\n","  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6) \n","   # Random crop back to the original size\n","  image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3])\n","  image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n","  image = tf.clip_by_value(image, 0, 1)\n","  return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Khu7amifqbni"},"source":["### Configure the datasets"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"khgl0CwEeZ-_","colab":{}},"source":["train_ds = (\n","    train_ds\n","    .shuffle(1000)\n","    .map(augment, num_parallel_calls=AUTOTUNE)\n","    .batch(batch_size)\n","    .prefetch(AUTOTUNE)\n",") "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4PUbgIYJebED","colab":{}},"source":["val_ds = (\n","    val_ds\n","    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n","    .batch(batch_size)\n","    .prefetch(AUTOTUNE)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nQvQzKoQgBw2","colab":{}},"source":["test_ds = (\n","    test_ds\n","    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n","    .batch(batch_size)\n","    .prefetch(AUTOTUNE)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hKwCA6AOjTrc"},"source":["These datasets can now be used to train a model as shown previously."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YypDihDlj0no"},"source":["## Next steps\n","\n","This tutorial demonstrated data augmentation using [Keras Preprocessing Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/) and `tf.image`. To learn how to include preprocessing layers inside your model, see the [Image classification](https://www.tensorflow.org/tutorials/images/classification) tutorial. You may also be interested in learning how preprocessing layers can help you classify text, as shown in the [Basic text classification](https://www.tensorflow.org/tutorials/keras/text_classification) tutorial. You can learn more about `tf.data` in this [guide](https://www.tensorflow.org/guide/data), and you can learn how to configure your input pipelines for performance [here](https://www.tensorflow.org/guide/data_performance)."]}]}